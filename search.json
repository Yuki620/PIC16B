[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "PIC 16B - 2024 Winter Blog"
  },
  {
    "objectID": "posts/Homework1/index.html",
    "href": "posts/Homework1/index.html",
    "title": "HW 1",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport sqlite3"
  },
  {
    "objectID": "posts/Homework1/index.html#data-wrangling-and-visualization",
    "href": "posts/Homework1/index.html#data-wrangling-and-visualization",
    "title": "HW 1",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport sqlite3"
  },
  {
    "objectID": "posts/Homework1/index.html#creating-a-database",
    "href": "posts/Homework1/index.html#creating-a-database",
    "title": "HW 1",
    "section": "1. Creating a Database",
    "text": "1. Creating a Database\nFirst, we will create a database called temps.db as shown below, and then read in the csv file as an iterator that gives a dataframe with up to 100,000 rows each iteration for more efficient processing time and memory storage.\n\n# Create a database in current directory called temps.db\nconn = sqlite3.connect(\"temps.db\")\n\n\n# Read in the csv file as an iterator with up to 100,000 observations each iteration\ndf_iter = pd.read_csv(\"temps.csv\", chunksize=100000)\n\n\nPreparing the temperatures table\nNow we will inspect the dataframe.\n\ndf = df_iter.__next__()\n\n\ndf.head()\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\nThe first table we want to put into the database is temperatures, so we will need to restructure the dataframe so that we get a cleaner look. Therefore, we will write a function as shown below to prepare our table.\n\ndef prepare_df(df):\n    # Stack the table with ID and Year as the index\n    df = df.set_index(keys=['ID', 'Year'])   \n    df = df.stack()\n    df = df.reset_index()\n    \n    df = df.rename(columns={\"level_2\": \"Month\", 0: \"Temp\"}) # Rename the columns with clearer labels\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int) # Extract just the numerical value as the month\n    df[\"Temp\"] = df[\"Temp\"] / 100 \n    \n    return(df)\n\n\n\nPreparing the countries table\nWe acquire a data frame that gives the full country name corresponding to the FIPS (Federal Information Processing System) code. The FIPS code is an internationally standardized abbreviation for a country:\nAs shown below, we now have the temperatures table we want and are ready to add it to the database!\n\ncountries_url = \"https://raw.githubusercontent.com/mysociety/gaze/master/data/fips-10-4-to-iso-country-codes.csv\"\ncountry = pd.read_csv(countries_url)\ncountry.head(5)\n\n\n\n\n\n\n\n\nFIPS 10-4\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n\n\n\n\n\nThe first 2 letters of ID are the same as the letters given in FIPS 10-4! Therefore, we write a function below to prepare the countries table such that it will contain all the unique IDs and the countries they correspond to.\n\ndef merge_country(df, countries):\n    df[\"FIPS 10-4\"] = df[\"ID\"].str[:2] # Extract the Country Code\n    df = pd.merge(df, country, on=\"FIPS 10-4\") # Merge FIPS Code with the temp dataframe\n    df = df.drop([\"FIPS 10-4\", \"ISO 3166\", \"Year\", \"Month\", \"Temp\"], axis=1) # Drop all unnecessary columns\n    df = df.drop_duplicates() # Drop the duplicate observations\n    return(df)\n\n\n\nAdding the temperatures and countries tables\nThe code below adds the temperatures and countries tables to the database.\n\ndf_iter = pd.read_csv(\"temps.csv\", chunksize=100000) # run this again to make sure no chunks are skipped over\nfor i, df in enumerate(df_iter):\n    df = prepare_df(df)\n    # add \"temperatures\" table to the database\n    df.to_sql(\"temperatures\", conn, if_exists=\"replace\" if i==0 else \"append\", index=False)\n    countries = merge_country(df, country)\n    # add \"countries\" table to the database\n    countries.to_sql(\"countries\", conn, if_exists=\"replace\" if i==0 else \"append\", index=False)\n\n\n\nAdding the stations table\nNow we want to add in the stations table. Since it is not a large csv file, we can just read it in directly.\n\nstations = pd.read_csv(\"station-metadata.csv\")\nstations.to_sql(\"stations\", conn, if_exists=\"replace\", index=False)\n\n27585\n\n\n\n\nVerification\nWith the code below, we can verify that all 3 tables were successfully added into the database.\n\nfor i, df_chunk in enumerate(df_country):\n    countries = merge_country(df, country)\n    # add \"countries\" table to the database\n    countries.to_sql(\"countries\", conn, if_exists=\"replace\" if i==0 else \"append\", index=False)\n\n\ncursor = conn.cursor() # we can only execute sql commands through cursor\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\nprint(cursor.fetchall())\n\n[('stations',), ('countries',), ('temperatures',)]\n\n\n\n\nClose the database connection\n\nconn.close()"
  },
  {
    "objectID": "posts/Homework1/index.html#write-a-query-function",
    "href": "posts/Homework1/index.html#write-a-query-function",
    "title": "HW 1",
    "section": "2. Write a Query Function",
    "text": "2. Write a Query Function\nquery_climate_database()accepts five arguments:\n\ndb_file, the file name for the database\ncountry, a string giving the name of a country for which data should be returned.\nyear_begin and year_end, two integers giving the earliest and latest years for which should be returned.\nmonth, an integer giving the month of the year for which should be returned.\n\nThe return value of query_climate_database() is a Pandas dataframe of temperature readings for the specified country, in the specified date range, in the specified month of the year. This dataframe should have the following columns, in this order:\n\nNAME: The station name.\nLATITUDE: The latitude of the station.\nLONGITUDE: The longitude of the station.\nCountry: The name of the country in which the station is located.\nYear: The year in which the reading was taken.\nMonth: The month in which the reading was taken.\nTemp: The average temperature at the specified station during the specified year and month.\n\n\nImport query_climate_database()\n\nfrom climate_database import query_climate_database\nimport inspect\nprint(inspect.getsource(query_climate_database))\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    with sqlite3.connect(db_file) as conn:\n        # conn is automatically closed when this block ends\n\n        # NAME, LATITUDE, LONGITUDE, Country, Year, Month, Temp\n        cmd = \\\n        f\"\"\"\n        SELECT S.NAME, S.LATITUDE, S.LONGITUDE, C.NAME as Country, T.Year, T.Month, T.Temp \n        FROM temperatures T\n        LEFT JOIN stations S ON T.ID = S.ID\n        LEFT JOIN countries C on T.ID = C.ID\n        WHERE T.Month = {month} \n            AND T.Year &gt;= {year_begin} \n            AND T.Year &lt;= {year_end}\n            AND C.NAME = '{country}'\n        \"\"\"\n        df = pd.read_sql_query(cmd, conn)\n    return df"
  },
  {
    "objectID": "posts/Homework0/index.html",
    "href": "posts/Homework0/index.html",
    "title": "HW 0",
    "section": "",
    "text": "In this tutorial, we will be plotting a scatterplot between the Palmer Penguins’ flipper lengths and body mass to see how they compare and differ across the 3 species.\n\n\nFirst, we want to import pandas for data manipulation and seaborn for visualization.\n\nimport pandas as pd\nimport seaborn as sns\n\n\n\n\nUsing pandas, we can load in the Palmers Penguins dataset with URL below.\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n\n\nUsing pandas, we can subset the dataframe so that we have only the necessary components. In this case, we only need the columns: Species, Flipper Length (mm), and Body Mass (g)\n\ndf = penguins[[\"Species\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\n\n\n\n\nUsing seaborn, we can plot the scatterplot easily by using seaborn.scatterplot and setting “Flipper Length (mm)” as the x-axis and “Body Mass (g)” as the y-axis.\nIn order to group the points by species, we can differentiate the points through shape and color by setting the parameters style and hue to “Species.”\nBecause the full species names are unnecessarily long, we can change the labels of the legend by accessing it through the code scatter.legend_ and setting new labels as shown below.\n\nscatter = sns.scatterplot(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", \n                          style=\"Species\", hue=\"Species\", data=df)\n\n# set scatterplot title\nscatter.set(title='Flipper Length & Body Mass By Species') \n\n# Access Legend\nlegend = scatter.legend_\nnew_labels = ['Adelie', 'Chinstrap', 'Gentoo']\nlegend.set_title('Species') # set legend title\nfor t, l in zip(legend.texts, new_labels): t.set_text(l) # add in the new labels"
  },
  {
    "objectID": "posts/Homework0/index.html#palmer-penguins-visualization-tutorial",
    "href": "posts/Homework0/index.html#palmer-penguins-visualization-tutorial",
    "title": "HW 0",
    "section": "",
    "text": "In this tutorial, we will be plotting a scatterplot between the Palmer Penguins’ flipper lengths and body mass to see how they compare and differ across the 3 species.\n\n\nFirst, we want to import pandas for data manipulation and seaborn for visualization.\n\nimport pandas as pd\nimport seaborn as sns\n\n\n\n\nUsing pandas, we can load in the Palmers Penguins dataset with URL below.\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n\n\nUsing pandas, we can subset the dataframe so that we have only the necessary components. In this case, we only need the columns: Species, Flipper Length (mm), and Body Mass (g)\n\ndf = penguins[[\"Species\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\n\n\n\n\nUsing seaborn, we can plot the scatterplot easily by using seaborn.scatterplot and setting “Flipper Length (mm)” as the x-axis and “Body Mass (g)” as the y-axis.\nIn order to group the points by species, we can differentiate the points through shape and color by setting the parameters style and hue to “Species.”\nBecause the full species names are unnecessarily long, we can change the labels of the legend by accessing it through the code scatter.legend_ and setting new labels as shown below.\n\nscatter = sns.scatterplot(x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", \n                          style=\"Species\", hue=\"Species\", data=df)\n\n# set scatterplot title\nscatter.set(title='Flipper Length & Body Mass By Species') \n\n# Access Legend\nlegend = scatter.legend_\nnew_labels = ['Adelie', 'Chinstrap', 'Gentoo']\nlegend.set_title('Species') # set legend title\nfor t, l in zip(legend.texts, new_labels): t.set_text(l) # add in the new labels"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UCLA PIC 16B Lec 1, Winter 2024",
    "section": "",
    "text": "HW 1\n\n\n\n\n\n\nWeek 1\n\n\nHomework\n\n\n\n\n\n\n\n\n\nJan 18, 2024\n\n\nYuki Yu\n\n\n\n\n\n\n\n\n\n\n\n\nHW 0\n\n\n\n\n\n\nWeek 0\n\n\nHomework\n\n\n\n\n\n\n\n\n\nJan 8, 2024\n\n\nYuki Yu\n\n\n\n\n\n\nNo matching items"
  }
]