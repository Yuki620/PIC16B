{
 "cells": [
  {
   "cell_type": "raw",
   "id": "28e8be87",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Web Scraping TMDB - 'Wonka'\"\n",
    "author: \"Yuki Yu\"\n",
    "date: \"2024-01-28\"\n",
    "categories: [Web Scraping, Python]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f66ce",
   "metadata": {},
   "source": [
    "## Web Scraping TMDB - \"Wonka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07801fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad826bf3",
   "metadata": {},
   "source": [
    "### 1. Setting Up the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008032bb",
   "metadata": {},
   "source": [
    "### 1.1 Pick a Movie \n",
    "Pick your favorite movie, and locate its TMDB page by searching on https://www.themoviedb.org/. For example, I like the movie Wonka. Its TMDB page is at:\n",
    "\n",
    "    https://www.themoviedb.org/movie/787699-wonka/\n",
    "    \n",
    "Save this URL for a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6f4f5",
   "metadata": {},
   "source": [
    "### 1.2 Dry-Run Navigation\n",
    "Now, we’re just going to click through the navigation steps that our scraper will take.\n",
    "\n",
    "First, click on the Full Cast & Crew link. This will take you to a page with URL of the form\n",
    "\n",
    "\\<original_url\\>/cast\n",
    "\n",
    "Next, scroll until you see the Cast section. Click on the portrait of one of the actors. This will take you to a page with a different-looking URL.\n",
    "\n",
    "Finally, scroll down until you see the actor’s Acting section. Note the titles of a few movies and TV shows in this section.\n",
    "\n",
    "Our scraper is going to replicate this process. Starting with your favorite movie, it’s going to look at all the actors in that movie, and then log all the other movies or TV shows that they worked on.\n",
    "\n",
    "At this point, it would be a good idea for you to use the Developer Tools on your browser to inspect individual HTML elements and look for patterns among the names you are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3603517",
   "metadata": {},
   "source": [
    "### 1.3. Initialize Your Project\n",
    "Open a terminal and type:\n",
    "\n",
    "    conda activate PIC16B\n",
    "    scrapy startproject TMDB_scraper\n",
    "    cd TMDB_scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aa7a0",
   "metadata": {},
   "source": [
    "### 1.4 Tweak Settings\n",
    "For now, add the following line to the file settings.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7f0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOSESPIDER_PAGECOUNT = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc1629",
   "metadata": {},
   "source": [
    "This line just prevents your scraper from downloading too much data while you’re still testing things out. You’ll remove this line later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a0185",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "If you run into `403 Forbidden` errors from the website detecting that you're a bot, follow the following steps: \n",
    "<br>\n",
    "\n",
    "**Installed `scrapy_fake_useragent`** <br>\n",
    "Make sure that it is installed in the correct environment and location. <br>\n",
    "\n",
    "**Add the following lines in `settings.py`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ff272",
   "metadata": {},
   "source": [
    "This setting is used to specify the amount of time (in seconds) that the scraper should wait before downloading consecutive pages from the same website. A DOWNLOAD_DELAY helps in mimicking human browsing behavior more closely and reduces the risk of getting banned or blocked by the website's server for sending too many requests too quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b22f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_DELAY = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c16a94",
   "metadata": {},
   "source": [
    "Some websites use cookies to detect and block scrapers. If the website's functionality you are scraping does not require cookies, disabling them can simplify your scraping process. Setting COOKIES_ENABLED to False turns off cookie handling, meaning your scraper won't send or receive any cookies with the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551000d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COOKIES_ENABLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614985d",
   "metadata": {},
   "source": [
    "The goal of these settings is to make the scraper mimic a real user's browsing behavior more closely and to improve its ability to access web pages by avoiding detection based on User-Agent patterns or being blocked due to repeated requests from the same User-Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d39309bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADER_MIDDLEWARES = {\n",
    "    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n",
    "    'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n",
    "    'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n",
    "    'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n",
    "}\n",
    "\n",
    "FAKEUSERAGENT_PROVIDERS = [\n",
    "    'scrapy_fake_useragent.providers.FakeUserAgentProvider',  # This is the first provider we'll try\n",
    "    'scrapy_fake_useragent.providers.FakerProvider',  # If FakeUserAgentProvider fails, we'll use faker to generate a user-agent string for us\n",
    "    'scrapy_fake_useragent.providers.FixedUserAgentProvider',  # Fall back to USER_AGENT value\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6846bce",
   "metadata": {},
   "source": [
    "### 2. Write Your Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440af53",
   "metadata": {},
   "source": [
    "Create a file inside the `spiders` directory called `tmdb_spider.py`. Add the following lines to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run \n",
    "# scrapy crawl tmdb_spider -O results.csv -a subdir=787699-wonka\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class TmdbSpider(scrapy.Spider):\n",
    "    name = 'tmdb_spider'\n",
    "    def __init__(self, subdir=None, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the instance with a start URL for a specific movie database subsection.\n",
    "\n",
    "        Parameters:\n",
    "        - subdir (str, optional): Subdirectory for the base URL, defaults to None.\n",
    "        - *args: Additional positional arguments.\n",
    "        - **kwargs: Additional keyword arguments.\n",
    "\n",
    "        Sets the start_urls attribute to a list containing the constructed URL.\n",
    "        \"\"\"\n",
    "        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ca9d6",
   "metadata": {},
   "source": [
    "Then, you will be able to run your completed spider for a movie of your choice by giving its subdirectory on TMDB website as an extra command-line argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435c24d",
   "metadata": {},
   "source": [
    "Now implement the following 3 parsing methods in the `TmdbSpider` class as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2e79d",
   "metadata": {},
   "source": [
    "`parse(self, response)` should assume that you start on a movie page, and then navigate to the Full Cast & Crew page. Remember that this page has url <movie_url>cast. (You are allowed to hardcode that part.) Once there, the parse_full_credits(self,response) should be called, by specifying this method in the callback argument to a yielded scrapy.Request. The parse() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, response):\n",
    "    \"\"\"\n",
    "    Initiates a request to the 'Full Cast & Crew' page of a movie.\n",
    "\n",
    "    Parameters:\n",
    "    - response: The response object from the initial movie page.\n",
    "\n",
    "    Yields:\n",
    "    - A scrapy.Request to the 'Full Cast & Crew' page, specifying parse_full_credits\n",
    "      as the callback method.\n",
    "    \"\"\"\n",
    "    cast_page = response.url + '/cast'\n",
    "    yield scrapy.Request(cast_page, callback=self.parse_full_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47c880",
   "metadata": {},
   "source": [
    "`parse_full_credits(self, response)` should assume that you start on the Full Cast & Crew page. Its purpose is to yield a scrapy.Request for the page of each actor listed on the page. Crew members are not included. The yielded request should specify the method parse_actor_page(self, response) should be called when the actor’s page is reached. The parse_full_credits() method does not return any data. This method should be no more than 5 lines of code, excluding comments and docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_full_credits(self, response):\n",
    "    \"\"\"\n",
    "    Yields requests for each actor's page from the 'Full Cast & Crew' page.\n",
    "\n",
    "    Parameters:\n",
    "    - response: The response object from the 'Full Cast & Crew' page.\n",
    "\n",
    "    Yields:\n",
    "    - scrapy.Request objects for each actor's page, with parse_actor_page as the callback.\n",
    "    \"\"\"\n",
    "    # extract the links for each actor\n",
    "    actor_links = response.css('ol.people.credits:not(.crew) li a::attr(href)').extract() \n",
    "\n",
    "    for link in actor_links:\n",
    "        # use response.urljoin to get the absolute link!\n",
    "        full_url = response.urljoin(link)\n",
    "        yield scrapy.Request(full_url, callback = self.parse_actor_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb919375",
   "metadata": {},
   "source": [
    "`parse_actor_page(self, response)` should assume that you start on the page of an actor. It should yield a dictionary with two key-value pairs, of the form `{\"actor\" : actor_name, \"movie_or_TV_name\" : movie_or_TV_name}`. The method should yield one such dictionary for each of the movies or TV shows on which that actor has worked in an acting role. Note that you will need to determine both the name of the actor and the name of each movie or TV show. This method should be no more than 15 lines of code, excluding comments and docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_actor_page(self, response):\n",
    "    \"\"\"\n",
    "    Yields dictionaries for each acting role of the actor, including the actor's name and the project's name.\n",
    "\n",
    "    Parameters:\n",
    "    - response: The response object from an actor's page.\n",
    "\n",
    "    Yields:\n",
    "    - A dictionary for each role, with keys 'actor' for the actor's name, and \n",
    "      'movie_or_TV_name' for the name of each movie or TV show they have acted in.\n",
    "    \"\"\"\n",
    "    # extract actor name\n",
    "    actor_name = response.css('h2.title a::text').get().strip()\n",
    "        \n",
    "    # Make sure we only select the 'Acting'\n",
    "    h3_elements = response.css('div.credits_list h3')\n",
    "    for h3 in h3_elements:\n",
    "        if 'Acting' in h3.xpath('./text()').get():\n",
    "            acting_table = h3.xpath('following-sibling::table[1]').get()\n",
    "            break\n",
    "    table_selector = Selector(text=acting_table)\n",
    "\n",
    "    for credit in table_selector.css('table.credit_group tr'):\n",
    "        # extract movie or tv show name\n",
    "        movie_or_TV_name = credit.css('td.role a.tooltip bdi::text').get().strip()\n",
    "        yield {\n",
    "            'actor': actor_name,\n",
    "            'movie_or_TV_name': movie_or_TV_name\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8e43f",
   "metadata": {},
   "source": [
    "Provided that these methods are correctly implemented, you can run the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8700888",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy crawl tmdb_spider -o results.csv -a subdir=787699-wonka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c2510",
   "metadata": {},
   "source": [
    "to create a `.csv` file with a column for actors and a column for movies or TV shows for \"Wonka\" (-o to append, and -O to overwrite file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791f32a",
   "metadata": {},
   "source": [
    "### 3. Make Your Recommendations\n",
    "Once your spider is fully written, comment out the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "346caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOSESPIDER_PAGECOUNT = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74407e",
   "metadata": {},
   "source": [
    "in the `settings.py` file. Then, the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72288823",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy crawl tmdb_spider -O results.csv -a subdir=787699-wonka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12b73a",
   "metadata": {},
   "source": [
    "will run your spider and save a CSV file called `results.csv`, with columns for actor names and the movies and TV shows on which they featured in.\n",
    "\n",
    "Once you’re happy with the operation of your spider, compute a sorted list with the top movies and TV shows that share actors with your favorite movie or TV show.\n",
    "\n",
    "**Prepare the Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a86423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_or_TV_name</th>\n",
       "      <th>number of shared actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Weird Al' Yankovic: Alpocalypse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Weird Al' Yankovic: White &amp; Nerdy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Minute Tales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100 Questions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102 Dalmatians</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie_or_TV_name  number of shared actors\n",
       "0    'Weird Al' Yankovic: Alpocalypse                        1\n",
       "1  'Weird Al' Yankovic: White & Nerdy                        1\n",
       "2                     10 Minute Tales                        1\n",
       "3                       100 Questions                        1\n",
       "4                      102 Dalmatians                        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "df = df.groupby('movie_or_TV_name').size().reset_index(name='number of shared actors')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327eed8",
   "metadata": {},
   "source": [
    "**Sort the Table** <br>\n",
    "Since \"Wonka\" would obviously have the highest amount of shared actors, we will exclude it from our recommendation table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef80988c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_or_TV_name</th>\n",
       "      <th>number of shared actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peep Show</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paddington 2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death in Paradise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paddington</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Midsomer Murders</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Graham Norton Show</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Horrible Histories</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ghosts</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Doctor Who</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_or_TV_name  number of shared actors\n",
       "1                Peep Show                        8\n",
       "2             Paddington 2                        7\n",
       "3        Death in Paradise                        6\n",
       "4               Paddington                        6\n",
       "5         Midsomer Murders                        6\n",
       "6   The Graham Norton Show                        6\n",
       "7             Black Mirror                        6\n",
       "8       Horrible Histories                        6\n",
       "9                   Ghosts                        5\n",
       "10              Doctor Who                        5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='number of shared actors', ascending=False)\n",
    "df.index = range(0, len(df))\n",
    "df = df.iloc[1:11,]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f11f0",
   "metadata": {},
   "source": [
    "**Make the Bar Chart with Plotly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f00af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_4.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(df, x='movie_or_TV_name', y='number of shared actors' \n",
    "            ,title=\"Recommendations after \\\"Wonka\\\"\"\n",
    "            ,labels={\n",
    "                \"movie_or_TV_name\": \"Movie or TV Name\",\n",
    "                \"number of shared actors\": \"Number of Shared Actors\"\n",
    "            })\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=30, b=0))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
